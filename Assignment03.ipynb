{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shannonlal/Statistical-YCBS-255/blob/main/Assignment03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2unLOmVzsBK"
      },
      "source": [
        "\n",
        "# Assignment 3  <font color=\"blue\"> (15 points) </font>\n",
        " \n",
        "***\n",
        "\n",
        "### Notes and Instructions\n",
        "  + You may need additional libraries besides the Python standard library to solve some questions. Import only necessary libraries. \n",
        "  + If more than one library exist for a same purpose, choose the one you wish as long as it does the task properly. \n",
        "  + If we want you to use a specific library, then we will state it clearly. \n",
        "  + Use the exact variable names asked in the questions. When no clear instructions given, feel free to do it the way you would like to.\n",
        "  + After each question, add the needed number of new cells and place your answers inside the cells. \n",
        "  + Use text cells for explanations. Use explanation and plain text as much as possible. \n",
        "  + Do not remove or modify the original cells provided by the instructor.\n",
        "  + In the following cell you will find some extra options to make your code more readable, including output colors RED, OKBLUE, or output text styles like BOLD or UNDERLINE that. Do not hesitate to use them. As an example, one may output text in red as follows: \n",
        "  ```python\n",
        "     print(bcolors.RED + \"your text\" + bcolors.ENDC)\n",
        "  ```\n",
        "  + Comment your code whenever needed using # sign at the beginning of the row.\n",
        "  + In some questions some of the details needed for solving the problem are **purposely** omitted to encourage additional self-directed research. This, especially, helps you develop some search skills for coding in Python (which is inevitable due to the inconsistent syntax of Python).\n",
        "  + Do not hesitate to communicate your questions to the TA's or instructors. \n",
        "    \n",
        "  Good luck! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOt20LC3zsBN"
      },
      "source": [
        "# The following piece of code gives the opportunity to show multiple outputs\n",
        "# in one cell:\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "\n",
        "# Colorful outputs\n",
        "class bcolors:\n",
        "    RED       = '\\033[91m'\n",
        "    OKBLUE    = '\\033[94m'\n",
        "    BOLD      = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    ENDC      = '\\033[0m'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports for workbook\n",
        "# Load Libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "g6xMxiAL8tIV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhunulGDzsBS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI8k_3Wp2qVH"
      },
      "source": [
        "## **Part A** <font color=\"blue\">(5 points)</font>\n",
        "\n",
        "1. **<font color=\"blue\">(1 point)</font>** Generate 100 points equally distanced from $-20$ to $20$ and save them in a `numpy` array `x1`. Now, create $4$ more `numpy` arrays by raising `x1` to the power of $2,3,4,5$, and call them `x2`, `x3`, `x4` and `x5`, respectively. \n",
        "3. **<font color=\"blue\">(1 point)</font>** Create your response `y`, a new `numpy` array, defined as $y= 1.75 + 5 x_1 + 0.05 x_3 - 10.3 x_5 + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, 4)$.\n",
        "4. **<font color=\"blue\">(2 points)</font>** Using $5$-fold cross-validation, with a reasonable train-test proportion, train a **lasso** regression model including all $x_1, x_2, x_3 , x_4 , x_5$, and for $10$ different  pre-determined tuning parameters. \n",
        "5. **<font color=\"blue\">(1 point)</font>** Plot the **cross-validated mean squared errors** vs the tuning parameter's values\n",
        " and chose the best tuning parameter based on the plot. Does the best model chosen perform **variable selection**?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part A Generate 100 points equally distanced from  âˆ’20  to  20  and save them in a numpy array x1. \n",
        "#Now, create  4  more numpy arrays by raising x1 to the power of  2,3,4,5 , and call them x2, x3, x4 and x5, \n",
        "# respectively.\n",
        "x1 = np.linspace( -20, 20, 100 )\n",
        "x1 = np.array( x1 ).reshape( -1,1)\n",
        "\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.power.html\n",
        "x2 = np.power ( x1, 2)\n",
        "x3 = np.power ( x1, 3)\n",
        "x4 = np.power ( x1, 4)\n",
        "x5 = np.power ( x1, 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "dnQMD-mI8bn0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part A, Q2: Create your response y, a new numpy array, defined as ð‘¦=1.75+5ð‘¥1+0.05ð‘¥3âˆ’10.3ð‘¥5+ðœ€, where  ðœ€âˆ¼îˆº(0,4)\n",
        "# This function follows the generic formula:\n",
        "# y = B0 + B1x1 + B2x3 + B3x5 + ðœ€\n",
        "\n",
        "## Define known constants\n",
        "B0 = 1.75\n",
        "B1 = 5\n",
        "B2 = 0.05\n",
        "B3 = 10.3\n",
        "\n",
        "## Calculate ðœ€ with a normal distribution with mean of 0 and standard deviation of 4\n",
        "## We will use the formula from numpy to get a normal distribution\n",
        "## np.random.normal (p)\n",
        "## We need 3 variables: mean, standard deviation spread, size\n",
        "## Size: is 100\n",
        "## mean = 0\n",
        "## standard deviation: sqrt(4)\n",
        "size = 100\n",
        "mu = 0\n",
        "std_dev = np.sqrt(4)\n",
        "np.random.seed(1)     # Fixing a seed\n",
        "e = np.random.normal(mu, std_dev, size)\n",
        "\n",
        "y = B0 + B1*x1 + B2*x3 + B3*x5 + e\n",
        "\n",
        "print( y )\n"
      ],
      "metadata": {
        "id": "6xeV153lXMq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4910864c-9b6d-489a-810c-9660bdc1b810"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-32960495.00130928 -32960499.47351283 -32960499.30634351 ...\n",
            "  -32960498.16280629 -32960499.49000169 -32960496.85393593]\n",
            " [-29763003.00773814 -29763007.4799417  -29763007.31277237 ...\n",
            "  -29763006.16923515 -29763007.49643056 -29763004.8603648 ]\n",
            " [-26818621.63635956 -26818626.10856311 -26818625.94139379 ...\n",
            "  -26818624.79785657 -26818626.12505198 -26818623.48898622]\n",
            " ...\n",
            " [ 26818631.63374101  26818627.16153746  26818627.32870678 ...\n",
            "   26818628.472244    26818627.1450486   26818629.78111435]\n",
            " [ 29763013.00511962  29763008.53291606  29763008.70008539 ...\n",
            "   29763009.8436226   29763008.5164272   29763011.15249296]\n",
            " [ 32960504.99869073  32960500.52648718  32960500.6936565  ...\n",
            "   32960501.83719372  32960500.50999831  32960503.14606407]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T1LSVx9pnXIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Junk Notes\n",
        "\n",
        "\n",
        "\n",
        "# Look at assignment #4\n",
        "\n",
        "# #2 Part B, Q7\n",
        "lasso_regression = Lasso(alpha=0.5)\n",
        "\n",
        "# Don't use Y\n",
        "data = np.concatenate((y,x1,x2,x3,x4,x5), axis = 1)\n",
        "\n",
        "# Question 3\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "k = 5\n",
        "kf = KFold(n_splits = k)\n",
        "# kf.get_n_splits(X)\n",
        "X = data[:,1:6]\n",
        "y = data[:,0]\n",
        "\n",
        "# # For each decision_threshold the following must be done\n",
        "threshold_mean_accuracy =  np.zeros(len(decision_threshold)) # mean accuracy of each threshold\n",
        "for i in range(len(decision_threshold)):\n",
        "    threshold = decision_threshold[i]\n",
        "    print('Threshold: ', threshold)\n",
        "    mae_lasso0 = 0\n",
        "\n",
        "    for train_index, test_index in kf.split(data):\n",
        "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        lasso_regression = Lasso(alpha=0.5)\n",
        "        lasso_regression.fit(X_train,y_train)\n",
        "        print('R^2:',lasso_regression.score(X_train,y_train))\n",
        "        y_pred_lasso = lasso_regression.predict(X_test)\n",
        "        mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "        print(f'mae_lasso: {mae_lasso}')\n",
        "        \n",
        "        #predicts = np.where(lasso_regression.predict_proba(X_test)[:,1] > threshold, 1, 0)\n",
        "        mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "        mae_lasso0 = mae_lasso0 + mae_lasso\n",
        "\n",
        "        for train_index, test_index in kf.split(data):\n",
        "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "# Workbook 4\n"
      ],
      "metadata": {
        "id": "WXflP-3cnacR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKnyVWq21kZ9"
      },
      "source": [
        "## **Part B** <font color=\"blue\">(3 points)</font>\n",
        "For this part upload `Wage.csv`.\n",
        "\n",
        "1. **<font color=\"blue\">(2 points)</font>** Perform polynomial regression to predict `wage` using `age`. Use cross-validation to select the optimal degree $d$ for the polynomial. What degree was chosen? Make a plot of\n",
        "the resulting polynomial fit to the data. \n",
        "2. **<font color=\"blue\">(1 point)</font>** Fit a step function to predict `wage` using `age` , and perform cross-validation to choose the optimal number of cuts. Make a plot of the fit obtained.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Look at workbook 6 for polynimal Regression"
      ],
      "metadata": {
        "id": "MuA0bX_rbubU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GLQakVZ41gL"
      },
      "source": [
        "\n",
        "## **Part C** <font color=\"blue\">(4 points)</font>\n",
        "Apply SVM and random forests to a data set of your choice. Be sure to fit the models on a training set and to evaluate their performance on a test set. How accurate are the results compared to each other? Which of them yields the best performance?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUCsQMN0UV5m"
      },
      "source": [
        "## **Part D** <font color=\"blue\">(3 points)</font>\n",
        "\n",
        "1. **<font color=\"blue\">(1 point)</font>** Generate $2$-dimentional data with $500$ observations from $3$ Gaussian clusters. \n",
        "2. **<font color=\"blue\">(0.5 points)</font>** Use a scatterplot to visualize the produced data. \n",
        "3. **<font color=\"blue\">(1 point)</font>** Shuffle the data and use $K$-means, with $K=2,3,4$ to cluster the data.\n",
        "4. **<font color=\"blue\">(0.5 points)</font>** Visualize the results, separately.  \n"
      ]
    }
  ]
}